{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1d0dfd6",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "[SciPy](http://www.scipy.org) builds on top of NumPy to provide common tools for scientific programming such as\n",
    "\n",
    "* [linear algebra](http://docs.scipy.org/doc/scipy/reference/linalg.html)\n",
    "* [numerical integration](http://docs.scipy.org/doc/scipy/reference/integrate.html)\n",
    "* [interpolation](http://docs.scipy.org/doc/scipy/reference/interpolate.html)\n",
    "* [optimization](http://docs.scipy.org/doc/scipy/reference/optimize.html)\n",
    "* [distributions and random number generation](http://docs.scipy.org/doc/scipy/reference/stats.html)\n",
    "* [signal processing](http://docs.scipy.org/doc/scipy/reference/signal.html)\n",
    "* etc., etc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6a2f4d",
   "metadata": {},
   "source": [
    "Many SciPy routines are thin wrappers around industry-standard Fortran libraries such as [LAPACK](https://en.wikipedia.org/wiki/LAPACK), [BLAS](https://en.wikipedia.org/wiki/Basic_Linear_Algebra_Subprograms), etc.\n",
    "\n",
    "It's not really necessary to \"learn\" SciPy as a whole.\n",
    "\n",
    "In this lecture, we aim only to highlight some useful parts of the package.\n",
    "\n",
    "The functionality of SciPy is in its sub-packages\n",
    "\n",
    "* `scipy.optimize`, `scipy.integrate`, `scipy.stats`, etc.\n",
    "\n",
    "Let's explore some of the major sub-packages."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a6e4456",
   "metadata": {},
   "source": [
    "## Statistics\n",
    "\n",
    "The `scipy.stats` subpackage supplies\n",
    "\n",
    "* numerous random variable objects (densities, cumulative distributions, random sampling, etc.)\n",
    "* some estimation procedures\n",
    "* some statistical tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0366495e",
   "metadata": {},
   "source": [
    "### Random Variables and Distributions\n",
    "\n",
    "Recall that `numpy.random` provides functions for generating random variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7aaa1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.beta(5, 5, size=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c163b09e",
   "metadata": {},
   "source": [
    "This generates a draw from the distribution with the density function below when `a, b = 5, 5`\n",
    "\n",
    "$$\n",
    "f(x; a, b) = \\frac{x^{(a - 1)} (1 - x)^{(b - 1)}}\n",
    "    {\\int_0^1 u^{(a - 1)} (1 - u)^{(b - 1)} du}\n",
    "    \\qquad (0 \\leq x \\leq 1)\n",
    "$$\n",
    "\n",
    "Sometimes we need access to the density itself, or the cdf, the quantiles, etc.\n",
    "\n",
    "For this, we can use `scipy.stats`, which provides all of this functionality as well as random number generation in a single consistent interface.\n",
    "\n",
    "Here's an example of usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84158ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from scipy.stats import beta\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "q = beta(5, 5)      # Beta(a, b), with a = b = 5\n",
    "obs = q.rvs(2000)   # 2000 observations\n",
    "grid = np.linspace(0.01, 0.99, 100)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.hist(obs, bins=40, density=True)\n",
    "ax.plot(grid, q.pdf(grid), 'k-', linewidth=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e959811",
   "metadata": {},
   "source": [
    "The object `q` that represents the distribution has additional useful methods, including"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c895fe29",
   "metadata": {},
   "outputs": [],
   "source": [
    "q.cdf(0.4)      # Cumulative distribution function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503e00d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "q.ppf(0.8)      # Quantile (inverse cdf) function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a61353",
   "metadata": {},
   "outputs": [],
   "source": [
    "q.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d923a0c1",
   "metadata": {},
   "source": [
    "## Roots and Fixed Points\n",
    "\n",
    "A **root** or **zero** of a real function $f$ on $[a,b]$ is an $x \\in [a, b]$ such that $f(x)=0$.\n",
    "\n",
    "For example, if we plot the function\n",
    "\n",
    "$$\n",
    "f(x) = \\sin(4 (x - 1/4)) + x + x^{20} - 1\n",
    "$$\n",
    "\n",
    "with $x \\in [0,1]$ we get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98dd7f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = lambda x: np.sin(4 * (x - 1/4)) + x + x**20 - 1\n",
    "x = np.linspace(0, 1, 100)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(x, f(x), label='$f(x)$')\n",
    "ax.axhline(ls='--', c='k')\n",
    "ax.set_xlabel('$x$', fontsize=12)\n",
    "ax.set_ylabel('$f(x)$', fontsize=12)\n",
    "ax.legend(fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "802cfded",
   "metadata": {},
   "source": [
    "The unique root is approximately 0.408.\n",
    "\n",
    "Let's consider some numerical techniques for finding roots."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a6579d2",
   "metadata": {},
   "source": [
    "### Bisection \n",
    "\n",
    "One of the most common algorithms for numerical root-finding is *bisection*.\n",
    "\n",
    "To understand the idea, recall the well-known game where\n",
    "\n",
    "* Player A thinks of a secret number between 1 and 100\n",
    "* Player B asks if it's less than 50\n",
    "    * If yes, B asks if it's less than 25\n",
    "    * If no, B asks if it's less than 75\n",
    "\n",
    "And so on.\n",
    "\n",
    "This is bisection.\n",
    "\n",
    "SciPy provides a bisection function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48179bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import bisect\n",
    "\n",
    "bisect(f, 0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822f4838",
   "metadata": {},
   "source": [
    "### The Newton-Raphson Method \n",
    "\n",
    "\n",
    "Another very common root-finding algorithm is the [Newton-Raphson method](https://en.wikipedia.org/wiki/Newton%27s_method).\n",
    "\n",
    "In SciPy this algorithm is implemented by `scipy.optimize.newton`.\n",
    "\n",
    "Unlike bisection, the Newton-Raphson method uses local slope information in an attempt to increase the speed of convergence.\n",
    "\n",
    "Let's investigate this using the same function $f$ defined above.\n",
    "\n",
    "With a suitable initial condition for the search we get convergence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4916e231",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import newton\n",
    "\n",
    "newton(f, 0.2)   # Start the search at initial condition x = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415cef42",
   "metadata": {},
   "source": [
    "But other initial conditions lead to failure of convergence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c0f6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "newton(f, 0.7)   # Start the search at x = 0.7 instead"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0677e42b",
   "metadata": {},
   "source": [
    "### Hybrid Methods\n",
    "\n",
    "A general principle of numerical methods is as follows:\n",
    "\n",
    "* If you have specific knowledge about a given problem, you might be able to exploit it to generate efficiency.\n",
    "* If not, then the choice of algorithm involves a trade-off between speed and robustness.\n",
    "\n",
    "In practice, most default algorithms for root-finding, optimization and fixed points use *hybrid* methods.\n",
    "\n",
    "These methods typically combine a fast method with a robust method in the following manner:\n",
    "\n",
    "1. Attempt to use a fast method\n",
    "1. Check diagnostics\n",
    "1. If diagnostics are bad, then switch to a more robust algorithm\n",
    "\n",
    "In `scipy.optimize`, the function `brentq` is such a hybrid method and a good default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4bd2fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import brentq\n",
    "\n",
    "brentq(f, 0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbbb79b8",
   "metadata": {},
   "source": [
    "Here the correct solution is found and the speed is better than bisection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf81ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit brentq(f, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd285c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit bisect(f, 0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48552d0d",
   "metadata": {},
   "source": [
    "## Optimization \n",
    "\n",
    "Most numerical packages provide only functions for *minimization*.\n",
    "\n",
    "Maximization can be performed by recalling that the maximizer of a function $f$ on domain $D$ is\n",
    "the minimizer of $-f$ on $D$.\n",
    "\n",
    "Minimization is closely related to root-finding: For smooth functions, interior optima correspond to roots of the first derivative.\n",
    "\n",
    "The speed/robustness trade-off described above is present with numerical optimization too.\n",
    "\n",
    "Unless you have some prior information you can exploit, it's usually best to use hybrid methods.\n",
    "\n",
    "For constrained, univariate (i.e., scalar) minimization, a good hybrid option is `fminbound`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1a8d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import fminbound\n",
    "\n",
    "fminbound(lambda x: x**2, -1, 2)  # Search in [-1, 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9d5a9e",
   "metadata": {},
   "source": [
    "## Integration \n",
    "\n",
    "Most numerical integration methods work by computing the integral of an approximating polynomial.\n",
    "\n",
    "The resulting error depends on how well the polynomial fits the integrand, which in turn depends on how \"regular\" the integrand is.\n",
    "\n",
    "In SciPy, the relevant module for numerical integration is `scipy.integrate`.\n",
    "\n",
    "A good default for univariate integration is `quad`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b29c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.integrate import quad\n",
    "\n",
    "integral, error = quad(lambda x: x**2, 0, 1)\n",
    "integral"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
